{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Simple dynamic seq2seq with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potapov Anatoly MIPT student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "based on https://github.com/ematvey/tensorflow-seq2seq-tutorials/blob/master/1-seq2seq.ipynb\n",
    "\n",
    "also some recepies from http://web.stanford.edu/class/cs20si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For saving checkpoints.\n",
    "model_name = 'basic_seq2seq'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Problem 3\n",
    "(difficult!)\n",
    "\n",
    "Write a sequence-to-sequence LSTM which mirrors all the words in a sentence. For example, if your input is:\n",
    "  \n",
    "    the quick brown fox\n",
    "  \n",
    "the model should attempt to output:\n",
    " \n",
    "    eht kciuq nworb xof\n",
    " \n",
    "Refer to the lecture on how to put together a sequence-to-sequence model, as well as this article for best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later.\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load text corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified text8.zip\n"
     ]
    }
   ],
   "source": [
    "url = 'http://mattmahoney.net/dc/'\n",
    "\n",
    "def maybe_download(filename, expected_bytes):\n",
    "    \"\"\"\n",
    "    Download a file if not present, and make sure it's the right size.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        filename, _ = urlretrieve(url + filename, filename)\n",
    "    statinfo = os.stat(filename)\n",
    "    if statinfo.st_size == expected_bytes:\n",
    "        print('Found and verified %s' % filename)\n",
    "    else:\n",
    "        print(statinfo.st_size)\n",
    "        raise Exception(\n",
    "            'Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
    "    return filename\n",
    "\n",
    "filename = maybe_download('text8.zip', 31344016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Read data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 100000000\n"
     ]
    }
   ],
   "source": [
    "def read_data(filename):\n",
    "    f = zipfile.ZipFile(filename)\n",
    "    for name in f.namelist():\n",
    "        return tf.compat.as_str(f.read(name))\n",
    "    f.close()\n",
    "\n",
    "text = read_data(filename)\n",
    "print('Data size %d' % len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here we implement plain seq2seq â€” forward-only encoder + decoder without attention.  [Sutskever, Vinyals and Le (2014)](https://arxiv.org/abs/1409.3215). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Architecture diagram from their paper:\n",
    "![seq2seq architecutre](pictures/1-seq2seq.png)\n",
    "Rectangles are encoder and decoder's recurrent layers. Encoder receives `[A, B, C]` sequence as inputs. We don't care about encoder outputs, only about the hidden state it accumulates while reading the sequence. After input sequence ends, encoder passes its final state to decoder, which receives `[<EOS>, W, X, Y, Z]` and is trained to output `[W, X, Y, Z, <EOS>]`. `<EOS>` token is a special word in vocabulary that signals to decoder the beginning of translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implementation details\n",
    "\n",
    "TensorFlow has its own [implementation of seq2seq](https://www.tensorflow.org/tutorials/seq2seq/). Recently it was moved from core examples to [`tensorflow/models` repo](https://github.com/tensorflow/models/tree/master/tutorials/rnn/translate), and uses deprecated seq2seq implementation. Deprecation happened because it uses **static unrolling**.\n",
    "\n",
    "**Static unrolling** involves construction of computation graph with a fixed sequence of time step. Such a graph can only handle sequences of specific lengths. One solution for handling sequences of varying lengths is to create multiple graphs with different time lengths and separate the dataset into this buckets.\n",
    "\n",
    "**Dynamic unrolling** instead uses control flow ops to process sequence step by step. In TF this is supposed to more space efficient and just as fast. This is now a recommended way to implement RNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Vocabulary\n",
    "\n",
    "Seq2seq maps sequence onto another sequence. Both sequences consist of integers from a fixed range. In language tasks, integers usually correspond to words: we first construct a vocabulary by assigning to every word in our corpus a serial integer. First few integers are reserved for special tokens. We'll call the upper bound on vocabulary a `vocabulary size`.\n",
    "\n",
    "Input data consists of sequences of integers.\n",
    "In our task integers correspond to chars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Building a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Simple seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Encoder starts with empty state and runs through the input sequence. We are not interested in encoder's outputs, only in its `final_state`.\n",
    "\n",
    "Decoder uses encoder's `final_state` as its `initial_state`. Its inputs are a batch-sized matrix with `<EOS>` token at the 1st time step and `<PAD>` at the following. This is a rather crude setup, useful only for tutorial purposes. In practice, we would like to feed previously generated tokens after `<EOS>`.\n",
    "\n",
    "Decoder's outputs are mapped onto the output space using `[hidden_units x output_vocab_size]` projection layer. This is necessary because we cannot make `hidden_units` of decoder arbitrarily large, while our target space would grow with the size of the dictionary.\n",
    "\n",
    "This kind of encoder-decoder is forced to learn fixed-length representation (specifically, `hidden_units` size) of the variable-length input sequence and restore output sequence only from this representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model inputs and outputs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First critical thing to decide: vocabulary size.\n",
    "\n",
    "Dynamic RNN models can be adapted to different batch sizes and sequence lengths without retraining (e.g. by serializing model parameters and Graph definitions via `tf.train.Saver`), but changing vocabulary size requires retraining the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify vocabulary and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EOS': 1, 'PAD': 0, ' ': 2, 'a': 3, 'c': 5, 'b': 4, 'e': 7, 'd': 6, 'g': 9, 'f': 8, 'i': 11, 'h': 10, 'k': 13, 'j': 12, 'm': 15, 'l': 14, 'o': 17, 'n': 16, 'q': 19, 'p': 18, 's': 26, 'r': 20, 'u': 23, 't': 22, 'w': 25, 'v': 24, 'y': 28, 'x': 27, 'z': 29}\n",
      "[3, 4, 5]\n",
      "[' ', 'a', 'b']\n"
     ]
    }
   ],
   "source": [
    "voc = {}\n",
    "voc['PAD'] = 0\n",
    "voc['EOS'] = 1\n",
    "voc[' '] = 2\n",
    "\n",
    "alph = 'abcdefghijklmnopqrstuvwsxyz'\n",
    "ind = 3\n",
    "for l in alph:\n",
    "    voc[l] = ind\n",
    "    ind+=1\n",
    "print(voc)\n",
    "\n",
    "rev_voc = {v: k for k, v in voc.iteritems()}\n",
    "\n",
    "def encode(arr):\n",
    "    return [voc.get(ch,-1) for ch in arr]\n",
    "\n",
    "def decode(arr):\n",
    "    return [rev_voc.get(ch,'UNK') for ch in arr]\n",
    "\n",
    "print(encode(list('abc')))\n",
    "print(decode([2, 3, 4]))\n",
    "\n",
    "def get_bucket(text, length):\n",
    "    words = np.random.choice(text.split(' ')[1:], length)\n",
    "    return([encode(list(word)) for word in words])\n",
    "    \n",
    "def reverse(bucket):\n",
    "    return([word[::-1] for word in bucket])\n",
    "    \n",
    "bucket = get_bucket(text[:1000], 10)\n",
    "rev_bucket = reverse(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = len(voc)\n",
    "input_embedding_size = 2 * len(voc)\n",
    "\n",
    "encoder_hidden_units = 300\n",
    "decoder_hidden_units = encoder_hidden_units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice way to understand complicated function is to study its signature - inputs and outputs. With pure functions, only inputs-output relation matters.\n",
    "\n",
    "- `encoder_inputs` int32 tensor is shaped `[encoder_max_time, batch_size]`\n",
    "- `decoder_targets` int32 tensor is shaped `[decoder_max_time, batch_size]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We'll add one additional placeholder tensor: \n",
    "- `decoder_inputs` int32 tensor is shaped `[decoder_max_time, batch_size]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We actually don't want to feed `decoder_inputs` manually â€” they are a function of either `decoder_targets` or previous decoder outputs during rollout. However, there are different ways to construct them. It might be illustrative to explicitly specify them for out first seq2seq implementation.\n",
    "\n",
    "During training, `decoder_inputs` will consist of `<EOS>` token concatenated with `decoder_targets` along time axis. In this way, we always pass target sequence as the history to the decoder, regrardless of what it actually outputs predicts. This can introduce distribution shift from training to prediction. \n",
    "In prediction mode, model will receive tokens it previously generated (via argmax over logits), not the ground truth, which would be unknowable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice that all shapes are specified with `None`s (dynamic). We can use batches of any size with any number of timesteps. This is convenient and efficient, however but there are obvious constraints: \n",
    "- Feed values for all tensors should have same `batch_size`\n",
    "- Decoder inputs and ouputs (`decoder_inputs` and `decoder_targets`) should have same `decoder_max_time`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The centerpiece of all things RNN in TensorFlow is `RNNCell` class and its descendants (like `LSTMCell` and `InputProjectionWrapper`). But they are outside of the scope of this post â€” nice [official tutorial](https://www.tensorflow.org/tutorials/recurrent/) is available. While at it, make sure you're also familiar with the [official tutorial on embeddings](https://www.tensorflow.org/tutorials/word2vec/).\n",
    "\n",
    "`@TODO: RNNCell as a factory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.rnn import (LSTMCell,\n",
    "                                    InputProjectionWrapper,\n",
    "                                    OutputProjectionWrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "encoder_cell = LSTMCell(encoder_hidden_units)\n",
    "\n",
    "encoder_cell = InputProjectionWrapper(cell=encoder_cell, num_proj=input_embedding_size)\n",
    "\n",
    "encoder_inputs_onehot = tf.one_hot(encoder_inputs, depth=vocab_size, dtype=tf.float32)\n",
    "\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, encoder_inputs_onehot,\n",
    "    dtype=tf.float32, time_major=True,\n",
    ")\n",
    "\n",
    "del encoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Observe what is going on here:\n",
    "- `encoder_inputs`, integer tensor with shape `[max_time, batch_size]`, gets one-hot encoded. Every integer at the every timestep in every batch gets transformed into a vector with size `vocab_size` that forms the new inner dimension. Resulting `encoder_inputs_onehot` is shaped `[max_time, batch_size, vocab_size]`. It consists of a single 1 and (vocab_size-1) 0s, but we want it to be float32 since we're going to multiply it with projection layer's weights.\n",
    "- `InputProjectionWrapper` adds `[vocab_size, hidden_units]` linear projection layer (without nonlinearities) before `LSTMCell`'s inputs. Resulting projection is shaped `[max_time, batch_size, hidden_units]` and is compatible with `LSTMCell`.\n",
    "\n",
    "There is more efficient way to get `[max_time, batch_size, hidden_units]` shape from `encoder_inputs`: `tf.nn.embedding_lookup`. Instead of one-hot encoding followed by matrix multiplication, it treats input integers as indices of projection layer's weights (this works because multiplication of one-hot vector with a dense matrix is exactly equivalent to indexing this matrix with an integer). Additionally, I think, it removes unnecessary compution of gradients for inactive embeddings (`@TODO: check, reformulate`).\n",
    "\n",
    "We discard `encoder_outputs` because we are not interested in them within seq2seq framework. What we actually want is `encoder_final_state` â€” state of LSTM's hidden cells at the last moment of the Encoder rollout.\n",
    "\n",
    "`encoder_final_state` is also called \"thought vector\". We will use it as initial state for the Decoder. In seq2seq without attention this is the only point where Encoder passes information to Decoder. We hope that backpropagation through time algorithm will tune the model to pass enough information in thought vector for correct output decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 300) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 300) dtype=float32>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "TensorFlow LSTM implementation stores state as a tuple of tensors. \n",
    "- `encoder_final_state.h` is activations of hidden layer of LSTM cell\n",
    "- `encoder_final_state.c` is final output, which can potentially be transfromed with some wrapper `@TODO: check correctness`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = LSTMCell(decoder_hidden_units)\n",
    "\n",
    "decoder_cell = InputProjectionWrapper(cell=decoder_cell, num_proj=input_embedding_size)\n",
    "\n",
    "decoder_cell = OutputProjectionWrapper(cell=decoder_cell, output_size=vocab_size)\n",
    "\n",
    "decoder_inputs_onehot = tf.one_hot(decoder_inputs, depth=vocab_size, dtype=tf.float32)\n",
    "\n",
    "decoder_logits, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    decoder_cell, decoder_inputs_onehot,\n",
    "\n",
    "    initial_state=encoder_final_state,\n",
    "\n",
    "    dtype=tf.float32, time_major=True, scope=\"plain_decoder\",\n",
    ")\n",
    "\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Since we pass `encoder_final_state` as `initial_state` to the decoder, they should be compatible. This means the same cell type (`LSTMCell` in our case), the same amount of `hidden_units` and the same amount of layers (single layer). I suppose this can be relaxed if we additonally pass `encoder_final_state` through a one-layer MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Decoder inputs get the same one-hot -> projection treatment as encoder inputs. But in case of the decoder, there is one more thing to do.\n",
    "\n",
    "With encoder, we were not interested in cells output. But decoder's outputs are what we actually after: we use them to get distribution over words of output sequence.\n",
    "\n",
    "At this point `decoder_cell` output is a `hidden_units` sized vector at every timestep. However, for training and prediction we need logits of size `vocab_size`. Reasonable thing would be to put linear layer on top of LSTM output to get non-normalized logits. This layer is called projection layer by convention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'plain_decoder/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 29) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "RNN outputs tensor of shape `[max_time, batch_size, hidden_units]` which projection layer maps onto `[max_time, batch_size, vocab_size]`. `vocab_size` part of the shape is static, while `max_time` and `batch_size` is dynamic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to form time-major batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch(inputs, max_sequence_length=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        inputs:\n",
    "            list of sentences (integer lists)\n",
    "        max_sequence_length:\n",
    "            integer specifying how large should `max_time` dimension be.\n",
    "            If None, maximum sequence length would be used\n",
    "    \n",
    "    Outputs:\n",
    "        inputs_time_major:\n",
    "            input sentences transformed into time-major matrix \n",
    "            (shape [max_time, batch_size]) padded with 0s\n",
    "        sequence_lengths:\n",
    "            batch-sized list of integers specifying amount of active \n",
    "            time steps in each input sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    sequence_lengths = [len(seq) for seq in inputs]\n",
    "    batch_size = len(inputs)\n",
    "    \n",
    "    if max_sequence_length is None:\n",
    "        max_sequence_length = max(sequence_lengths)\n",
    "    \n",
    "    inputs_batch_major = np.zeros(shape=[batch_size, max_sequence_length], dtype=np.int32) # == PAD\n",
    "    \n",
    "    for i, seq in enumerate(inputs):\n",
    "        for j, element in enumerate(seq):\n",
    "            inputs_batch_major[i, j] = element\n",
    "\n",
    "    # [batch_size, max_time] -> [max_time, batch_size]\n",
    "    inputs_time_major = inputs_batch_major.swapaxes(0, 1)\n",
    "\n",
    "    return inputs_time_major, sequence_lengths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test forward pass\n",
    "\n",
    "Did I say that deep learning is a game of shapes? When building a Graph, TF will throw errors when static shapes are not matching. However, mismatches between dynamic shapes are often only discovered when we try to run something through the graph.\n",
    "\n",
    "\n",
    "So let's try running something. For that we need to prepare values we will feed into placeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```\n",
    "this is key part where everything comes together\n",
    "\n",
    "@TODO: describe\n",
    "- how encoder shape is fixed to max\n",
    "- how decoder shape is arbitraty and determined by inputs, but should probably be longer then encoder's\n",
    "- how decoder input values are also arbitraty, and how we use GO token, and what are those 0s, and what can be used instead (shifted gold sequence, beam search)\n",
    "@TODO: add references\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_encoded:\n",
      "[[6 3 9]\n",
      " [0 4 8]\n",
      " [0 0 7]]\n",
      "decoder inputs:\n",
      "[[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "decoder predictions:\n",
      "[[ 9  2  2]\n",
      " [ 9 17  7]\n",
      " [17 17  7]\n",
      " [17 17 17]]\n"
     ]
    }
   ],
   "source": [
    "batch_ = [[6], [3, 4], [9, 8, 7]]\n",
    "batch_, batch_length_ = batch(batch_)\n",
    "print('batch_encoded:\\n' + str(batch_))\n",
    "\n",
    "din_, dlen_ = batch(np.ones(shape=(3, 1), dtype=np.int32),\n",
    "                            max_sequence_length=4)\n",
    "print('decoder inputs:\\n' + str(din_))\n",
    "\n",
    "pred_ = sess.run(decoder_prediction,\n",
    "    feed_dict={\n",
    "        encoder_inputs: batch_,\n",
    "        decoder_inputs: din_,\n",
    "    })\n",
    "print('decoder predictions:\\n' + str(pred_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Successful forward computation, everything is wired correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on our task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training data will consist of sentences from 1 to 4 words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "def batch_generator(text, word_min, word_max, batch_size):\n",
    "    \"\"\" Generates batches of random integer sequences,\n",
    "        sequence length in [length_from, length_to],\n",
    "        vocabulary in [vocab_lower, vocab_upper]\n",
    "    \"\"\"\n",
    "    words = text.split(' ')[1:]\n",
    "    \n",
    "    def stc(rev=False):\n",
    "        word_count = np.random.randint(low=word_min, high=word_max+1)\n",
    "        ind = np.random.randint(low=0, high=len(words) - word_count)\n",
    "        return [\n",
    "            encode(list(' '.join(words[ind:ind+word_count]))),\n",
    "            encode(list(' '.join(reverse(words[ind:ind+word_count]))))\n",
    "        ]\n",
    "            \n",
    "    while True:\n",
    "        yield [\n",
    "            stc()\n",
    "            for _ in range(batch_size)\n",
    "        ]\n",
    "    \n",
    "batches = batch_generator(text, word_min=1, word_max=4, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def next_feed(train_prob = 0.5):\n",
    "    b = batches.next()\n",
    "    encoder_inputs_, _ = batch(\n",
    "        [(sequence[0]) for sequence in b]\n",
    "    )\n",
    "    \n",
    "    # As we cannot feed decoder with its previous output during avaluation wi will need to\n",
    "    # include evaluation format into our batches\n",
    "    \n",
    "    if np.random.rand() < train_prob:\n",
    "        decoder_inputs_, _ = batch(\n",
    "            [[EOS] + (sequence[1]) + [PAD] * 2 for sequence in b]\n",
    "        )\n",
    "    else:\n",
    "        decoder_inputs_, _ = batch(\n",
    "            [[EOS] + [PAD] * (len(sequence[1])) + [PAD] * 2 for sequence in b]\n",
    "        )\n",
    "        \n",
    "    decoder_targets_, _ = batch(\n",
    "        [(sequence[1]) + [EOS] + [PAD] * 2 for sequence in b]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eeleptrting'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def form(arr, type = 'outp'):\n",
    "    \n",
    "    def ind(arr, elem):\n",
    "        return arr.index(elem) if elem in arr else len(arr)\n",
    "    \n",
    "    if type == 'outp':\n",
    "        return ''.join(arr[:ind(arr, 'EOS')])\n",
    "    if type == 'inp':\n",
    "        return ''.join(arr[:ind(arr, 'PAD')])\n",
    "\n",
    "form(['i', 'n', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'], 'inp')\n",
    "form(['e', 'e', 'l', 'e', 'p', 't', 'r', 't', 'i', 'n', 'g', 'EOS', 'PAD', 'PAD', 'PAD'], 'outp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore session if checkpoints exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint_directory/basic_seq2seq-40001\n"
     ]
    }
   ],
   "source": [
    "def restore(sess):\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoint_directory/{}'.format(model_name)))\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        \n",
    "restore(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "def progress(max):\n",
    "    p = IntProgress(max = max)\n",
    "    p.description = 'Running'\n",
    "    display(p)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have reduced train_prob from 1.0 to 0.01 during training to adapt model for evaluation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 41000\n",
      "  minibatch loss: 0.0675960406661\n",
      "  sample 1:\n",
      "    input     > way\n",
      "    predicted > yaw\n",
      "  sample 2:\n",
      "    input     > pow camp became the\n",
      "    predicted > wop pmac emaceb eht\n",
      "  sample 3:\n",
      "    input     > percentage\n",
      "    predicted > egatnecrep\n",
      "\n",
      "batch 42000\n",
      "  minibatch loss: 0.0604391023517\n",
      "  sample 1:\n",
      "    input     > seven four one\n",
      "    predicted > neves ruof eno\n",
      "  sample 2:\n",
      "    input     > be the\n",
      "    predicted > eb eht\n",
      "  sample 3:\n",
      "    input     > woods near boeotian\n",
      "    predicted > sdoow raen naitoeob\n",
      "\n",
      "batch 43000\n",
      "  minibatch loss: 0.0136740747839\n",
      "  sample 1:\n",
      "    input     > south america surviving\n",
      "    predicted > htuos acirema gnivivrus\n",
      "  sample 2:\n",
      "    input     > filio procedit in english\n",
      "    predicted > oilif tidecorp ni hsilgne\n",
      "  sample 3:\n",
      "    input     > ministry lion of judah\n",
      "    predicted > yrtsinim noil fo haduj\n",
      "\n",
      "batch 44000\n",
      "  minibatch loss: 0.0677925273776\n",
      "  sample 1:\n",
      "    input     > ii four are you\n",
      "    predicted > ii ruof era uoy\n",
      "  sample 2:\n",
      "    input     > the fact\n",
      "    predicted > eht tcaf\n",
      "  sample 3:\n",
      "    input     > maher american\n",
      "    predicted > reham nacirema\n",
      "\n",
      "batch 45000\n",
      "  minibatch loss: 0.0368267372251\n",
      "  sample 1:\n",
      "    input     > three louis\n",
      "    predicted > eerht siuol\n",
      "  sample 2:\n",
      "    input     > the codomain of\n",
      "    predicted > eht niamodoc fo\n",
      "  sample 3:\n",
      "    input     > to be\n",
      "    predicted > ot eb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_batches = 45001\n",
    "batches_in_epoch = 1000\n",
    "p = progress(max_batches)\n",
    "\n",
    "try:\n",
    "    for batch_num in range(sess.run(global_step), max_batches):\n",
    "        # Update progress bar.\n",
    "        p.value = batch_num\n",
    "        \n",
    "        fd = next_feed(train_prob = 0.01)\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "\n",
    "        if batch_num == 0 or batch_num % batches_in_epoch == 0:\n",
    "            # Save session.\n",
    "            saver.save(sess, 'checkpoint_directory/{}'.format(model_name),\n",
    "                       global_step=global_step)\n",
    "            \n",
    "            # Print examples.\n",
    "            print('batch {}'.format(batch_num))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(form(decode(inp),'inp')))\n",
    "                print('    predicted > {}'.format(form(decode(pred),'outp')))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0384 after 500000 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcff56a8350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Something is definitely getting learned. (some data lost when rerunning notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Limitations of the model\n",
    "\n",
    "We have no control over transitions of `tf.nn.dynamic_rnn`, it is unrolled in a single sweep\n",
    "\n",
    "- can't use beam search decoder optimization\n",
    "- can't feed previously generated tokens without falling back to python loops\n",
    "- can't use attention, because attention conditions decoder inputs on its previous state\n",
    "\n",
    "Solution would be to use `tf.nn.raw_rnn` to reimplement relevant parts of `tf.nn.dynamic_rnn`, add attention and beam search loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our model interractively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint_directory/basic_seq2seq-40001\n"
     ]
    }
   ],
   "source": [
    "restore(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_feed(stc):\n",
    "    length = len(stc)\n",
    "    \n",
    "    encoder_inputs_, _ = batch(\n",
    "        ([stc])\n",
    "    )\n",
    "    decoder_inputs_, _ = batch(\n",
    "        [[EOS] + [PAD] * (length+2)]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        decoder_inputs: decoder_inputs_\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how model performs with arbitrary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently executing fil\n",
      "    input     > currently executing fil\n",
      "    predicted > yltnerruc gnitucexe lif\n",
      "who had long\n",
      "    input     > who had long\n",
      "    predicted > xhw dah gnol\n",
      "same works correctly\n",
      "    input     > same works correctly\n",
      "    predicted > emas skrow yltcerroc\n",
      "been around longer than\n",
      "    input     > been around longer than\n",
      "    predicted > neeb dnuora regnol naht\n",
      "testing interrupted\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    while True:\n",
    "        stc = encode(str(raw_input()))\n",
    "        fd = prediction_feed(stc)\n",
    "        predict_ = sess.run(decoder_prediction, fd)\n",
    "        inp, pred = fd[encoder_inputs].T[0], predict_.T[0]\n",
    "        print('    input     > {}'.format(form(decode(inp),'inp')))\n",
    "        print('    predicted > {}'.format(form(decode(pred),'outp'))) \n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('testing interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "17b0cc81552c49c4846364fa40e7e67e": {
     "views": [
      {
       "cell_index": 70
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
